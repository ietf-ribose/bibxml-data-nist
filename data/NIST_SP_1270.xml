<reference anchor="NIST.SP.1270" target="https://doi.org/10.6028/NIST.SP.1270">
  <front>
    <title>Towards a standard for identifying and managing bias in artificial intelligence</title>
    <author fullname="Schwartz, Reva.">
      <organization/>
    </author>
    <author fullname="Vassilev, Apostol.">
      <organization/>
    </author>
    <author fullname="Greene, Kristen.">
      <organization/>
    </author>
    <author fullname="Perine, Lori.">
      <organization/>
    </author>
    <author fullname="Burt, Andrew.">
      <organization/>
    </author>
    <author fullname="Hall, Patrick.">
      <organization/>
    </author>
    <author>
      <organization>National Institute of Standards and Technology (U.S.)</organization>
    </author>
    <abstract>As individuals and communities interact in and with an environment that is increasingly virtual they are often vulnerable to the commodification of their digital exhaust. Concepts and behavior that are ambiguous in nature are captured in this environment, quantified, and used to categorize, sort, recommend, or make decisions about people's lives. While many organizations seek to utilize this information in a responsible manner, biases remain endemic across technology processes and can lead to harmful impacts regardless of intent. These harmful outcomes, even if inadvertent, create significant challenges for cultivating public trust in artificial intelligence (AI). SP 1270 is a NIST Artificial Intelligence publication and should be read in conjunction with all publications in the NIST AI Series, which was established in January 2023.</abstract>
  </front>
  <seriesInfo name="DOI" value="NIST.SP.1270"/>
  <seriesInfo name="NIST special publication; NIST special pub; NIST SP" value="1270"/>
</reference>