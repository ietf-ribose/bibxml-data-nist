<reference anchor="NIST.TN.2045" target="https://doi.org/10.6028/NIST.TN.2045">
  <front>
    <title>Confirming a performance threshold with a binary experimental response</title>
    <author fullname="Leber, Dennis D.">
      <organization/>
    </author>
    <author fullname="Pibida, Leticia.">
      <organization/>
    </author>
    <author fullname="Enders, Alexander L.">
      <organization/>
    </author>
    <author>
      <organization>Information Technology Laboratory (National Institute of Standards and Technology).</organization>
    </author>
    <abstract>When designing a test to confirm that an artifact (e.g., a radiation detection system) meets a performance threshold where the artifact's performance is estimated based on a binary response, the number of required observations is often an initial question. To determine the required sample size, two pieces of information are necessary: the performance threshold; and a statement of acceptable risk or required confidence. In this chapter, we provide guidance on developing a defensible and successful test through the informed selection of a performance threshold and statement of acceptable risk. Using the statistical hypothesis testing framework, we illustrate the meaning of risk and confidence from both the consumer and producer's perspectives. We define the power of a test and demonstrate how an experimenter can use a power curve to balance the tradeoffs between test burden (costs) and producer risk (type II error) while satisfying the required confidence. We provide a sample size and acceptance criterion table to define a fixed sample test that will satisfy a variety of performance thresholds and levels of acceptable risk. We conclude with a general discussion of sequential sampling tests and provide important considerations and contrasts to their fixed sample counterparts.</abstract>
  </front>
  <seriesInfo name="DOI" value="10.6028/NIST.TN.2045"/>
  <seriesInfo name="NIST technical note; NIST tech note; NIST TN" value="2045"/>
</reference>