<reference anchor="NIST.SP.2300-01" target="https://doi.org/10.6028/NIST.SP.2300-01">
  <front>
    <title>A review of community resilience indicators using a systems measurement framework</title>
    <author fullname="Dillard, Maria K.">
      <organization/>
    </author>
    <author fullname="Walpole, Emily.">
      <organization/>
    </author>
    <author fullname="Loerzel; Jarrod.">
      <organization/>
    </author>
    <author>
      <organization>National Institute of Standards and Technology (U.S.)</organization>
    </author>
    <abstract>As natural disasters have increased in frequency and magnitude, there has been an increasing need to understand what underlying factors are likely to lead to faster recovery and more resilient communities. One way of addressing this need has been to develop sets of indicators or indicator indices that serve as proxy measurements for resilience, which is an emergent system property and cannot be directly measured. Once operationalized, resilience indicators can be used for planning, making funding decisions, and tracking program progress. Since all of these uses can have profound effects on community well-being, it is important that indicator selection involves stakeholders and is based on the best available science. For the latter criteria, this can be determined by assessing what evidence is used to justify indicator choices and validating candidate indicators on observed data. Previous reviews of resilience indicator frameworks have attempted to gauge the state of evidence used for indicator selection by looking for consensus of indicator choices across different frameworks. Similar to a multi-expert elicitation, it is inferred that agreement on an indicator among frameworks points to strong evidence that the indicator is a good measurement of resilience. Using a novel categorization methodology based in systems science, this study reviews a small set of resilience frameworks for indicator consensus. Compared to previous reviews, this methodology allows for clear distinction between consensus of concepts and consensus of indicators to measure concepts. Our results show two new insights. The first is that common usage of an indicator does not mean that agreement also exists on what the indicator is actually measuring. The second is that even if a common indicator has agreement on what concepts are measured, it is not guaranteed that this consensus is backed by high quality evidence. These results call into question the practice of reviewing many frameworks to identify common indicators during model development, and instead points to the need for more detailed assessment of background evidence and indicator validation.</abstract>
  </front>
  <seriesInfo name="DOI" value="NIST.SP.2300-01"/>
  <seriesInfo name="NIST special publication" value="2300-01"/>
  <seriesInfo name="NIST special publication; NIST special pub; NIST SP" value="2300-01"/>
</reference>